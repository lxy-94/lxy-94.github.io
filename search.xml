<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>leetcode习题笔记1</title>
      <link href="/2020/10/11/leetcode-xi-ti-bi-ji-1/"/>
      <url>/2020/10/11/leetcode-xi-ti-bi-ji-1/</url>
      
        <content type="html"><![CDATA[<h2 id="1-两数之和"><a href="#1-两数之和" class="headerlink" title="1.两数之和"></a>1.两数之和</h2><h3 id="题目"><a href="#题目" class="headerlink" title="题目"></a>题目</h3><p>给定一个整数数组 nums 和一个目标值 target，请你在该数组中找出和为目标值的那 两个 整数，并返回他们的数组下标。</p><p>你可以假设每种输入只会对应一个答案。但是，数组中同一个元素不能使用两遍。</p><hr><h4 id="暴力枚举"><a href="#暴力枚举" class="headerlink" title="暴力枚举"></a>暴力枚举</h4><p>思路</p><p>枚举数组中的每一个数x，寻找数组中是否存在target-x。</p><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true">#    时间复杂度：O(N^2)</span><span class="token comment" spellcheck="true">#    空间复杂度：O(1)</span><span class="token keyword">class</span> <span class="token class-name">Solution</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">twoSum</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> nums<span class="token punctuation">:</span> List<span class="token punctuation">[</span>int<span class="token punctuation">]</span><span class="token punctuation">,</span> target<span class="token punctuation">:</span> int<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">></span> List<span class="token punctuation">[</span>int<span class="token punctuation">]</span><span class="token punctuation">:</span>        n <span class="token operator">=</span> len<span class="token punctuation">(</span>nums<span class="token punctuation">)</span>        <span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span>n<span class="token punctuation">)</span><span class="token punctuation">:</span>            <span class="token keyword">for</span> j <span class="token keyword">in</span> range<span class="token punctuation">(</span>i <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">,</span> n<span class="token punctuation">)</span><span class="token punctuation">:</span>                <span class="token keyword">if</span> nums<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">+</span> nums<span class="token punctuation">[</span>j<span class="token punctuation">]</span> <span class="token operator">==</span> target<span class="token punctuation">:</span>                    <span class="token keyword">return</span> <span class="token punctuation">[</span>i<span class="token punctuation">,</span> j<span class="token punctuation">]</span>        <span class="token keyword">return</span> <span class="token punctuation">[</span><span class="token punctuation">]</span></code></pre><h4 id="哈希表"><a href="#哈希表" class="headerlink" title="哈希表"></a>哈希表</h4><p>思路</p><p>利用Hash map记录值与索引的关系，并查找target-val的索引是否存在，如果存在且不等于目前val的索引，则返回。</p><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true">#    时间复杂度：O(N)</span><span class="token comment" spellcheck="true">#    空间复杂度：O(N)</span><span class="token keyword">class</span> <span class="token class-name">Solution</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">twoSum</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> nums<span class="token punctuation">:</span> List<span class="token punctuation">[</span>int<span class="token punctuation">]</span><span class="token punctuation">,</span> target<span class="token punctuation">:</span> int<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">></span> List<span class="token punctuation">[</span>int<span class="token punctuation">]</span><span class="token punctuation">:</span>        hashmap <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token punctuation">}</span>        <span class="token keyword">for</span> index<span class="token punctuation">,</span> val <span class="token keyword">in</span> enumerate<span class="token punctuation">(</span>nums<span class="token punctuation">)</span><span class="token punctuation">:</span>            hashmap<span class="token punctuation">[</span>val<span class="token punctuation">]</span> <span class="token operator">=</span> index        <span class="token keyword">for</span> index<span class="token punctuation">,</span> val <span class="token keyword">in</span> enumerate<span class="token punctuation">(</span>nums<span class="token punctuation">)</span><span class="token punctuation">:</span>            temp <span class="token operator">=</span> hashmap<span class="token punctuation">.</span>get<span class="token punctuation">(</span>target<span class="token operator">-</span>val<span class="token punctuation">)</span>            <span class="token keyword">if</span> temp <span class="token keyword">is</span> <span class="token operator">not</span> None <span class="token operator">and</span> temp <span class="token operator">!=</span> index<span class="token punctuation">:</span>                <span class="token keyword">return</span> <span class="token punctuation">[</span>index<span class="token punctuation">,</span> temp<span class="token punctuation">]</span>        <span class="token keyword">return</span> <span class="token punctuation">[</span><span class="token punctuation">]</span></code></pre><hr><h2 id="49-字母异位词分组"><a href="#49-字母异位词分组" class="headerlink" title="49.字母异位词分组"></a>49.字母异位词分组</h2><h3 id="题目-1"><a href="#题目-1" class="headerlink" title="题目"></a>题目</h3><p>给定一个字符串数组，将字母异位词组合在一起。字母异位词指字母相同，但排列不同的字符串。</p><hr><h4 id="利用-dict-get-函数"><a href="#利用-dict-get-函数" class="headerlink" title="利用 dict.get() 函数"></a>利用 <strong>dict.get() 函数</strong></h4><p><strong>思路</strong></p><p>当且仅当它们的排序字符串相等时，两个字符串时字母异位词。</p><p><strong>算法</strong></p><p>维护一个dict，首先枚举字符串，对每个字符串内部排序并转换成元组（字典的键为不可变类型），利用dict.get(key, [])，存在则返回值，不存在则返回[]。</p><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true">#    时间复杂度：O(N*K*log(K))</span><span class="token comment" spellcheck="true">#    空间复杂度：O(N*K)</span><span class="token keyword">class</span> <span class="token class-name">Solution</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">groupAnagrams</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> strs<span class="token punctuation">)</span><span class="token punctuation">:</span>        ans <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token punctuation">}</span>        <span class="token keyword">for</span> s <span class="token keyword">in</span> strs<span class="token punctuation">:</span>            key <span class="token operator">=</span> tuple<span class="token punctuation">(</span>sorted<span class="token punctuation">(</span>s<span class="token punctuation">)</span><span class="token punctuation">)</span>            ans<span class="token punctuation">[</span>key<span class="token punctuation">]</span> <span class="token operator">=</span> ans<span class="token punctuation">.</span>get<span class="token punctuation">(</span>key<span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">+</span> <span class="token punctuation">[</span>s<span class="token punctuation">]</span>        <span class="token keyword">return</span> list<span class="token punctuation">(</span>ans<span class="token punctuation">.</span>values<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span></code></pre><h4 id="计数分类"><a href="#计数分类" class="headerlink" title="计数分类"></a>计数分类</h4><p><strong>思路</strong></p><p>当且仅当它们的字符计数（每个字符的出现次数）相同时，两个字符串是字母异位词。</p><p><strong>算法</strong></p><p>将每个字符串s转换为字符数count，由26个非负整数组成，表示 \text{a}a，\text{b}b，\text{c}c 的数量等。我们使用这些计数作为哈希映射的基础。</p><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true">#    时间复杂度：O(N*K)</span><span class="token comment" spellcheck="true">#    空间复杂度：O(N*K)</span><span class="token keyword">class</span> <span class="token class-name">Solution</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">groupAnagrams</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> strs<span class="token punctuation">)</span><span class="token punctuation">:</span>        ans <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token punctuation">}</span>        <span class="token keyword">for</span> s <span class="token keyword">in</span> strs<span class="token punctuation">:</span>            count <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token operator">*</span><span class="token number">26</span>            <span class="token keyword">for</span> c <span class="token keyword">in</span> s<span class="token punctuation">:</span>                count<span class="token punctuation">[</span>ord<span class="token punctuation">(</span>c<span class="token punctuation">)</span> <span class="token operator">-</span> ord<span class="token punctuation">(</span><span class="token string">'a'</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">+=</span> <span class="token number">1</span>            key <span class="token operator">=</span> tuple<span class="token punctuation">(</span>count<span class="token punctuation">)</span>            ans<span class="token punctuation">[</span>key<span class="token punctuation">]</span> <span class="token operator">=</span> ans<span class="token punctuation">.</span>get<span class="token punctuation">(</span>key<span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">+</span><span class="token punctuation">[</span>s<span class="token punctuation">]</span>        <span class="token keyword">return</span> list<span class="token punctuation">(</span>ans<span class="token punctuation">.</span>values<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span></code></pre><h2 id="242-有效的字母异位词"><a href="#242-有效的字母异位词" class="headerlink" title="242. 有效的字母异位词"></a>242. 有效的字母异位词</h2><h3 id="题目-2"><a href="#题目-2" class="headerlink" title="题目"></a>题目</h3><p>给定两个字符串 <em>s</em> 和 <em>t</em> ，编写一个函数来判断 <em>t</em> 是否是 <em>s</em> 的字母异位词。</p><hr><h4 id="暴力枚举-1"><a href="#暴力枚举-1" class="headerlink" title="暴力枚举"></a>暴力枚举</h4><p>思路</p><p>对s与t分别排序，排序后的字符串如果相等，则为字母异位词。</p><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true">#    时间复杂度：O(N*log(N))</span><span class="token comment" spellcheck="true">#    空间复杂度：O(1)</span><span class="token keyword">class</span> <span class="token class-name">Solution</span><span class="token punctuation">(</span>object<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">isAnagram</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> s<span class="token punctuation">,</span> t<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">if</span> sorted<span class="token punctuation">(</span>s<span class="token punctuation">)</span> <span class="token operator">==</span> sorted<span class="token punctuation">(</span>t<span class="token punctuation">)</span><span class="token punctuation">:</span>            <span class="token keyword">return</span> <span class="token boolean">True</span>        <span class="token keyword">else</span><span class="token punctuation">:</span>            <span class="token keyword">return</span> <span class="token boolean">False</span></code></pre><h4 id="哈希表-1"><a href="#哈希表-1" class="headerlink" title="哈希表"></a>哈希表</h4><p>思路</p><p>对s与t分别构建哈希表，key为每个字符，index为出现的次数。</p><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true">#    时间复杂度：O(N)</span><span class="token comment" spellcheck="true">#    空间复杂度：O(N)</span><span class="token keyword">class</span> <span class="token class-name">Solution</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">isAnagram</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> s<span class="token punctuation">:</span> str<span class="token punctuation">,</span> t<span class="token punctuation">:</span> str<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">></span> bool<span class="token punctuation">:</span>        dict1<span class="token punctuation">,</span> dict2 <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token punctuation">}</span><span class="token punctuation">,</span> <span class="token punctuation">{</span><span class="token punctuation">}</span>        <span class="token keyword">for</span> item <span class="token keyword">in</span> s<span class="token punctuation">:</span>            dict1<span class="token punctuation">[</span>item<span class="token punctuation">]</span> <span class="token operator">=</span> dict1<span class="token punctuation">.</span>get<span class="token punctuation">(</span>item<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token operator">+</span><span class="token number">1</span>        <span class="token keyword">for</span> item <span class="token keyword">in</span> t<span class="token punctuation">:</span>            dict2<span class="token punctuation">[</span>item<span class="token punctuation">]</span> <span class="token operator">=</span> dict2<span class="token punctuation">.</span>get<span class="token punctuation">(</span>item<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token operator">+</span><span class="token number">1</span>        <span class="token keyword">return</span> dict1 <span class="token operator">==</span> dict2</code></pre>]]></content>
      
      
      
        <tags>
            
            <tag> leetcode </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>SinGAN论文解读</title>
      <link href="/2019/11/17/singan-lun-wen-jie-du/"/>
      <url>/2019/11/17/singan-lun-wen-jie-du/</url>
      
        <content type="html"><![CDATA[<p>﻿<a href="https://arxiv.org/pdf/1905.01164.pdf" target="_blank" rel="noopener">论文地址</a><br>这篇论文为ICCV2019最佳论文，主要贡献在于设计了一个基于单张图片的图像生成模型，并将其应用到多个方向，包括图像随机生成，图像融合、手绘画转自然图像、图像编辑以及图像超分重建。最近找时间将学习到的部分进行总结整理。</p><h2 id="创新点"><a href="#创新点" class="headerlink" title="创新点"></a>创新点</h2><ul><li>设计一种基于单张自然图像训练的非条件GAN网络（由噪声作为输入直接生成）；</li><li>无需修改模型，直接应用于多种图像任务；</li><li>GAN网络中的G网络与D网络具有相同的模型结构以及相同的感受野，并添加一种重建损失，保证GAN可以进行平稳训练；</li><li>设计一种coarse-to-fine的金字塔型GAN网络，每一层学习到前一层缺失的细节；</li></ul><h2 id="网络架构"><a href="#网络架构" class="headerlink" title="网络架构"></a>网络架构</h2><p><img src="https://img-blog.csdnimg.cn/20191116095035182.PNG?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NDk3NTg4Nw==,size_16,color_FFFFFF,t_70" alt="SinGAN网络模型"><br>上图为本论文使用的网络架构，由N个GAN网络组成金字塔形状的SinGAN结构。从训练到测试，论文都是基于Coarse-to-Fine思想，由下到上，尺度逐渐由粗糙到精细。在第n个尺度上，Gn网络的输入是第n+1个G网络的生成图像，经过上采样后与对应随机噪声相加的结果，学习生成图像样本，而D网络判断生成图像的真假。<br>值得一提的是，本论文的每一层D网络都是基于Patch判断的，经典的PatchD，从最粗糙层GN一直上升到最精细层G0，每个D的感受野固定，都是11*11，也就是说，在最粗糙的GN，patch大小为图像的1/2，此时GAN网络可以学习到图像的全局结构，而在最精细的G0，GAN网络学习的是局部细节。在此引用一篇解答文章，具体的公式如下：<br><img src="https://img-blog.csdnimg.cn/2019111610195583.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NDk3NTg4Nw==,size_16,color_FFFFFF,t_70" alt="多尺度结构"></p><h2 id="训练过程"><a href="#训练过程" class="headerlink" title="训练过程"></a>训练过程</h2><p><img src="https://img-blog.csdnimg.cn/20191116102117293.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NDk3NTg4Nw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>其中的重建损失保证最粗糙一层可以由噪声直接生成图像，保证了相近的图像风格。</p><h2 id="结果"><a href="#结果" class="headerlink" title="结果"></a>结果</h2><h3 id="生成的随机图像"><a href="#生成的随机图像" class="headerlink" title="生成的随机图像"></a>生成的随机图像</h3><p><img src="https://img-blog.csdnimg.cn/20191116102808916.PNG?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NDk3NTg4Nw==,size_16,color_FFFFFF,t_70" alt="生成的图像"><br>可以发现，SinGAN可以很好的学习图像的纹理和位置信息，同时对于阴影以及水中的倒影也有学习，不过第二行在夕阳下山峰的倒影并不是很真实，略微不符合自然规律。</p><h3 id="模型应用的不同结果"><a href="#模型应用的不同结果" class="headerlink" title="模型应用的不同结果"></a>模型应用的不同结果</h3><p><img src="https://img-blog.csdnimg.cn/20191116103338835.PNG?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NDk3NTg4Nw==,size_16,color_FFFFFF,t_70" alt></p><h3 id="SinGAN的层数的影响"><a href="#SinGAN的层数的影响" class="headerlink" title="SinGAN的层数的影响"></a>SinGAN的层数的影响</h3><p>下图显示在测试过程中SinGAN的层数对于最终图像的影响，在这里n=N表示从最粗糙部分完全由噪声生成，n=N-1表示由原始图像下采样并于噪声相加得到。<br><img src="https://img-blog.csdnimg.cn/20191117114632166.PNG?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NDk3NTg4Nw==,size_16,color_FFFFFF,t_70" alt="SinGAN不同层数的影响"></p><h3 id="训练层数的影响"><a href="#训练层数的影响" class="headerlink" title="训练层数的影响"></a>训练层数的影响</h3><p>下图展示了SinGAN网络应用不同训练层数对于最终生成图像的影响，可以发现，当仅使用2层GAN训练时，由于感受野受限，模型只能学习到局部细节，而缺乏全局信息，随着训练层数的提高SinGAN可以学习到更多的全局信息。<br><img src="https://img-blog.csdnimg.cn/20191117120257707.PNG?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NDk3NTg4Nw==,size_16,color_FFFFFF,t_70" alt="SinGAN训练层数的影响"></p><h2 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h2><p>本文介绍了一种可以从单幅自然图像中学习的新型非条件生成框架–SinGAN。证明了其可以学习单一图像的完全分布，从噪声完全生成具有逼真细节、清晰纹理的自然图像。</p><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p>文章：<a href="https://arxiv.org/pdf/1905.01164.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1905.01164.pdf</a><br>GitHub：<a href="https://github.com/tamarott/SinGAN/tree/master/SinGAN" target="_blank" rel="noopener">https://github.com/tamarott/SinGAN/tree/master/SinGAN</a><br>参考文献：<br><a href="http://www.dataguru.cn/article-15165-1.html" target="_blank" rel="noopener">http://www.dataguru.cn/article-15165-1.html</a></p><p>知乎：</p><p><a href="https://zhuanlan.zhihu.com/p/92218525" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/92218525</a></p><p>CSDN：</p><p><a href="https://blog.csdn.net/weixin_44975887/article/details/103089483" target="_blank" rel="noopener">https://blog.csdn.net/weixin_44975887/article/details/103089483</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> 论文 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>tensorboardX的Scalar使用详解</title>
      <link href="/2019/09/24/tensorboardx-de-scalar-shi-yong-xiang-jie/"/>
      <url>/2019/09/24/tensorboardx-de-scalar-shi-yong-xiang-jie/</url>
      
        <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>​        昨日想通过可视化的方式观察使用Pytorch训练的模型的loss下降趋势，以及模型框架，经过对比，选择tensorboardX。<strong>Github上的解决方案：**</strong><a href="https://github.com/lanpa/tensorboardX**。" target="_blank" rel="noopener">https://github.com/lanpa/tensorboardX**。</a></p><h2 id="依赖环境"><a href="#依赖环境" class="headerlink" title="依赖环境"></a>依赖环境</h2><p>Python 2.7+</p><p>Pytorch 0.4+</p><p>tensorboardX: pip install tensorboardX, pip install tensorflow</p><h2 id="代码教程"><a href="#代码教程" class="headerlink" title="代码教程"></a>代码教程</h2><h3 id="Scalar-教程"><a href="#Scalar-教程" class="headerlink" title="Scalar 教程"></a>Scalar 教程</h3><pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> numpy <span class="token keyword">as</span> npfrom tensorboardX <span class="token keyword">import</span> SummaryWriterwriter <span class="token operator">=</span> SummaryWriter<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">for</span> epoch <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">100</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        writer<span class="token punctuation">.</span>add_scalar<span class="token punctuation">(</span><span class="token string">'scalar/test'</span><span class="token punctuation">,</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> epoch<span class="token punctuation">)</span>           writer<span class="token punctuation">.</span>add_scalars<span class="token punctuation">(</span><span class="token string">'scalar/scalars_test'</span><span class="token punctuation">,</span> <span class="token punctuation">{</span><span class="token string">'xsinx'</span><span class="token punctuation">:</span> epoch<span class="token operator">*</span>np<span class="token punctuation">.</span>sin<span class="token punctuation">(</span>epoch<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">'xcosx'</span><span class="token punctuation">:</span> epoch<span class="token operator">*</span>np<span class="token punctuation">.</span>cos<span class="token punctuation">(</span>epoch<span class="token punctuation">)</span><span class="token punctuation">}</span><span class="token punctuation">,</span> epoch<span class="token punctuation">)</span>writer<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span></code></pre><p>​        writer = Summarywriter()有两个参数(log_dir=None, comment=‘’, **kwargs)，其中log_dir为生成的文件所存放的目录，comment为文件名称，默认目录生成runs文件夹目录。</p><p><img src="C:%5Cblog%5Cmyblog%5Csource_posts%5C1569274648075.png" alt></p><p>​        当SummaryWriter(comment=’base_scalar’)，生成结果为：</p><p><img src="C:%5Cblog%5Cmyblog%5Csource_posts%5C1569274748450.png" alt></p><p>​        writer.add_scalar()，这句话是将我们需要的数据保存在文件里供可视化使用。第一个参数理解为保存的名称，第二个参数为Y轴数据，第三个参数为X轴数据。我们在runs同级目录下使用命令行：tensorboard –logdir runs，如下所示：</p><p><img src="C:%5Cblog%5Cmyblog%5Csource_posts%5C1569275831694.png" alt></p><p>​        最终的效果图如下：</p><p><img src="C:%5Cblog%5Cmyblog%5Csource_posts%5C1569275879935.png" alt></p>]]></content>
      
      
      
        <tags>
            
            <tag> Pytorch </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>《稀缺》解读</title>
      <link href="/2019/08/24/xi-que-jie-du/"/>
      <url>/2019/08/24/xi-que-jie-du/</url>
      
        <content type="html"><![CDATA[<p>为什么穷人越穷，富人越富？怎样才能摆脱稀缺心态，摆脱贫穷。</p><h2 id="稀缺的构成"><a href="#稀缺的构成" class="headerlink" title="稀缺的构成"></a>稀缺的构成</h2><p>作者认为长期的贫穷会带来一种稀缺心态。稀缺心态有个好处，会带来专注红利：短时间内集中精力爆发出高度注意力，比如Deadline之前的几天，是工作效率最高的时候；再比如永远是假期结束前的几天，我们会格外珍惜它。虽然如此的专注会在短时间内带来一定的好处，但如果长时间处在这种稀缺心态，会把一个人拖向贫穷，进入一个匮乏的恶性循环。</p><h2 id="稀缺的危害"><a href="#稀缺的危害" class="headerlink" title="稀缺的危害"></a>稀缺的危害</h2><p>稀缺会带来四种效应：</p><ul><li><p>管窥效应：</p><p>目光短浅，只关注眼前狭窄范围内的紧急事情，在意短时间内的成败与得失，而忽略了长久的发展与积累的技能叠加带来的长期的影响力。</p></li><li><p>借用：</p><p>让一个人习惯性的透支未来的资源，比如透支信用卡，工作拖到下一周，人们往往会高估自己在明天的能力从而不注意提升今天的自己，比如时间管理，精力管理，提高工作效率。</p></li><li><p>没有余闲：</p><p>稀缺会让人把大量的精力投入在了时间与金钱之间权衡的思维过程。因为这样的权衡会让一个人产生大量的心智负担，会消耗注意力、精力，进一步产生管窥效应，让人只注重眼前的事情、忽略了重要的事情。余闲可能会让人不是100%忙碌，但却让人从容地面对生活，不需要过多纠结于小事的权衡，以及有一定容错率。</p></li><li><p>带宽的不足：</p><p>带宽是我们计算能力、关注能力、决策能力、执行能力和抵制诱惑能力的统称，这些能力支撑了我们各种各样的行为。穷人不服药、不除草、不买保险、不储蓄、不投资，都是因为他们不重视这些事情，他们真正缺的不是时间、金钱，而是带宽，亦或是对于这些事情的认知能力。所以要关注长期规划，学习新的技能、定期理财，才有可能跳出稀缺的怪圈。</p></li></ul><h2 id="预防稀缺产生"><a href="#预防稀缺产生" class="headerlink" title="预防稀缺产生"></a>预防稀缺产生</h2><p>不要局限自己的眼光，要把它放长远些，这和吴军博士提到的“见识决定了你能走多远”是一个道理。我们需要</p><ul><li>节约带宽：不要把时间浪费在琐事上，集中在可以长期积累的事情上；</li><li>留有余闲：不要透支未来，定期存储、按时休息，设置提醒；</li><li>设置提醒：把重要的事情拉回到视野中引起重视；</li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> 读书 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>深度学习的Attenton机制</title>
      <link href="/2019/08/15/shen-du-xue-xi-de-attenton-ji-zhi/"/>
      <url>/2019/08/15/shen-du-xue-xi-de-attenton-ji-zhi/</url>
      
        <content type="html"><![CDATA[<h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p>​        通常在计算机视觉的深度学习算法中，Attention机制基本思想是让系统学会注意力，可以自动关注那些我们希望它关注的重点信息。</p><h1 id="Attention"><a href="#Attention" class="headerlink" title="Attention"></a>Attention</h1><p>​       通常Attention机制被分为soft attention和hard attention，目前接触的算法通常都是soft attention机制。</p><h2 id="Soft-Attention"><a href="#Soft-Attention" class="headerlink" title="Soft Attention"></a>Soft Attention</h2><h3 id="空间域"><a href="#空间域" class="headerlink" title="空间域"></a>空间域</h3><p>​        空间注意力表现在模型对于图像的不同位置的关注程度不同。当特征图大小为 H×W×C，空间注意力对应着大小为H×W的矩阵，该矩阵的每个位置对原特征图对应位置的像素来讲就是一个权重，pixel-wise multiply。</p><p><img src="https://img2018.cnblogs.com/blog/1665919/201905/1665919-20190507160648693-2046757003.png" alt="img"></p><h2 id="通道域"><a href="#通道域" class="headerlink" title="通道域"></a>通道域</h2><p>​        这种注意力主要分布在channel中，相当于对图像的不同通道的关注程度不同。当特征图大小为 H×W×C，通道注意力对应着大小为1×1×C的矩阵，每个位置对应原channel图像全部像素的一个权重，channel-wise multiply。</p><p><img src="https://img2018.cnblogs.com/blog/1665919/201905/1665919-20190507161354647-1211359587.png" alt="img"></p>]]></content>
      
      
      
        <tags>
            
            <tag> 论文 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Leetcode.155</title>
      <link href="/2019/08/12/leetcode.155/"/>
      <url>/2019/08/12/leetcode.155/</url>
      
        <content type="html"><![CDATA[<h2 id="155-最小栈"><a href="#155-最小栈" class="headerlink" title="155.最小栈"></a>155.最小栈</h2><ul><li>设定一个辅助栈，用来存放<strong>stack</strong>中最小值：<ul><li>push:每当push新值进来时，如果“小于等于”min_stack栈顶值，则一起push到min_stack，即更新了最小值；</li><li>pop:判断pop出去的元素值是否是min_stack栈顶元素值（即最小值），如果是则将min_stack栈顶元素一起pop，这样可以保证min_stack栈顶元素始终是stack中的最小</li><li>getMin:返回min_stack栈顶即可。</li></ul></li><li>min_stack的作用是对stack中的元素做标记，标记的原则是min_stack中元素一定是降序的（栈底最大栈顶最小）。换个角度理解，min_stack等价于遍历stack所有元素，把升序的数字都删除掉，留下一个从栈底到栈顶降序的栈。本题要求获取最小值的复杂度是O(1)，因此须构建辅助栈，在push与pop的过程中始终保持辅助栈为一个降序栈。</li><li>时间空间复杂度都为O(N)，获取最小值复杂度为O(1)。</li></ul><pre class=" language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">MinStack</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token triple-quoted-string string">"""        initialize your data structure here.        """</span>        self<span class="token punctuation">.</span>stack <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>        self<span class="token punctuation">.</span>min_stack <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token keyword">def</span> <span class="token function">push</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">:</span> int<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">></span> None<span class="token punctuation">:</span>    self<span class="token punctuation">.</span>stack<span class="token punctuation">.</span>append<span class="token punctuation">(</span>x<span class="token punctuation">)</span>    <span class="token keyword">if</span> <span class="token operator">not</span> self<span class="token punctuation">.</span>min_stack <span class="token operator">or</span> x <span class="token operator">&lt;=</span> self<span class="token punctuation">.</span>min_stack<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">:</span>         self<span class="token punctuation">.</span>min_stack<span class="token punctuation">.</span>append<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token keyword">def</span> <span class="token function">pop</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">></span> None<span class="token punctuation">:</span>    <span class="token keyword">if</span> self<span class="token punctuation">.</span>stack<span class="token punctuation">.</span>pop<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">==</span> self<span class="token punctuation">.</span>min_stack<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">:</span>        self<span class="token punctuation">.</span>min_stack<span class="token punctuation">.</span>pop<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">def</span> <span class="token function">top</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">></span> int<span class="token punctuation">:</span>    <span class="token keyword">return</span> self<span class="token punctuation">.</span>stack<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token keyword">def</span> <span class="token function">getMin</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">></span> int<span class="token punctuation">:</span>    <span class="token keyword">return</span> self<span class="token punctuation">.</span>min_stack<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span></code></pre>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>爱如半夜汽笛</title>
      <link href="/2019/08/12/ai-ru-ban-ye-qi-di/"/>
      <url>/2019/08/12/ai-ru-ban-ye-qi-di/</url>
      
        <content type="html"><![CDATA[<h1 id="《爱如半夜汽笛》—-村上春树"><a href="#《爱如半夜汽笛》—-村上春树" class="headerlink" title="《爱如半夜汽笛》—- 村上春树"></a>《爱如半夜汽笛》—- 村上春树</h1><p>女孩问男孩：“你喜欢我喜欢到什么程度？” </p><p>少年想了想，用沉静的声音说：“半夜汽笛那个程度。” </p><p>少女默默地等待下文—里面肯定有什么故事。</p><p>“一次，半夜突然醒来。”他开始讲述，“确切时间不清楚，大约两三点吧，也就那个时间。什么时候并不重要，总之是夜深时分，我完完全全孤单一人，身边谁也没有。好吗，请你想象一下：四下漆黑一片，什么也看不见，什么也听不见，就连时钟声都听不见，也可能钟停了。我忽然觉得自己正被隔离开来，远离自己认识的人，远离自己熟悉的场所，远得无法置信。在这广大世界上不为任何人爱，不为任何人理解，不为任何人记起—我发现自己成了这样的存在。即使我就这么消失不见，也没有人察觉。那种心情，简直就像被塞进厚铁箱沉入深海底。由于气压的关系，心脏开始痛，痛得像要咔哧咔哧裂成两半。这滋味你可知道？”<br>　　少女点点头。想必她是知道的。<br>　　少年继续说道：“这大概是人活着的过程中所能体验到的最难以忍受的一种感觉。又伤心又难受，恨不得直接死掉算了。不不，不是这样，不是死掉算了，而是假如放在那里不管，就真的死掉了，因为铁箱里的空气越来越稀薄了。这可不是什么比喻，是真的。这也就是深夜里孤单单醒来的含义。这你也明白？”<br>　　少女再次默默点头。少年停了一会儿。<br>　　“不过当时听见很远很远的地方有汽笛声，非常非常遥远。到底什么地方有铁路呢？莫名其妙。总之就那么远。声音若有若无，但我知道那是火车的汽笛声，肯定是。黑暗中我竖耳细听，于是又一次听到了汽笛声。很快，我的心脏不再痛了，时针开始走动，铁箱朝海面慢慢浮升。而这都是因为那微弱的汽笛声的关系。汽笛声的确微弱，听见没听见都分不清，而我就像爱那汽笛一样爱你。”<br>　　少年的短小故事至此结束。这回少女开始讲她自己的故事。</p>]]></content>
      
      
      
        <tags>
            
            <tag> 散文 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Pytorch实现PixelShuffle</title>
      <link href="/2019/08/10/pytorch-shi-xian-pixelshuffle/"/>
      <url>/2019/08/10/pytorch-shi-xian-pixelshuffle/</url>
      
        <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>​        今天在思考如何解决model在上采样过程中可能会出现的棋盘格现象，阅读到一篇被CVPR2016收录的论文，里面提出了PixelShuffle，链接如下<a href="https://links.jianshu.com/go?to=https%3A%2F%2Farxiv.org%2Fabs%2F1609.05158" target="_blank" rel="noopener">《Real-Time Single Image and Video Super-Resolution Using an Efficient Sub-Pixel Convolutional Neural Network》</a>。</p><h2 id="过程"><a href="#过程" class="headerlink" title="过程"></a>过程</h2><p>​        PixelShuffle算法流程图如下，可以实现将h<em>w的低分辨率图像，通过sub-pixel 操作变为rh</em>rw的高分辨率图像，通过卷积层先得到了r^2个通道的图像，然后每个像素点的r^2个通道依次转换为对应的r<em>r的图像块，最终得到rh</em>rw的图像。</p><p><img src="https://upload-images.jianshu.io/upload_images/7812018-c33b5e4567bb5024.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1000/format/webp" alt="img"></p><p>​        Pytorch中已经集成了PixelShuffle的module，torch.nn.PixelShuffle(upscale_factor)，形参说明: - input (Variable) – 输入 - upscale_factor (int) – 增加空间分辨率的因子，例子如下。</p><p><img src="https://upload-images.jianshu.io/upload_images/7812018-b2a078e48dfd3084.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1000/format/webp" alt="img"></p>]]></content>
      
      
      
        <tags>
            
            <tag> Pytorch </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hello World</title>
      <link href="/2019/08/10/hello-world/"/>
      <url>/2019/08/10/hello-world/</url>
      
        <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="noopener">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="noopener">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="noopener">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><pre class=" language-bash"><code class="language-bash">$ hexo new <span class="token string">"My New Post"</span></code></pre><p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="noopener">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><pre class=" language-bash"><code class="language-bash">$ hexo server</code></pre><p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="noopener">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><pre class=" language-bash"><code class="language-bash">$ hexo generate</code></pre><p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="noopener">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><pre class=" language-bash"><code class="language-bash">$ hexo deploy</code></pre><p>More info: <a href="https://hexo.io/docs/deployment.html" target="_blank" rel="noopener">Deployment</a></p>]]></content>
      
      
      
    </entry>
    
    
  
  
</search>
