<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>tensorboardX的Scalar使用详解</title>
      <link href="/2019/09/24/tensorboardx-de-scalar-shi-yong-xiang-jie/"/>
      <url>/2019/09/24/tensorboardx-de-scalar-shi-yong-xiang-jie/</url>
      
        <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>​        昨日想通过可视化的方式观察使用Pytorch训练的模型的loss下降趋势，以及模型框架，经过对比，选择tensorboardX。<strong>Github上的解决方案：**</strong><a href="https://github.com/lanpa/tensorboardX**。" target="_blank" rel="noopener">https://github.com/lanpa/tensorboardX**。</a></p><h2 id="依赖环境"><a href="#依赖环境" class="headerlink" title="依赖环境"></a>依赖环境</h2><p>Python 2.7+</p><p>Pytorch 0.4+</p><p>tensorboardX: pip install tensorboardX, pip install tensorflow</p><h2 id="代码教程"><a href="#代码教程" class="headerlink" title="代码教程"></a>代码教程</h2><h3 id="Scalar-教程"><a href="#Scalar-教程" class="headerlink" title="Scalar 教程"></a>Scalar 教程</h3><pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> numpy <span class="token keyword">as</span> npfrom tensorboardX <span class="token keyword">import</span> SummaryWriterwriter <span class="token operator">=</span> SummaryWriter<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">for</span> epoch <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">100</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        writer<span class="token punctuation">.</span>add_scalar<span class="token punctuation">(</span><span class="token string">'scalar/test'</span><span class="token punctuation">,</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> epoch<span class="token punctuation">)</span>           writer<span class="token punctuation">.</span>add_scalars<span class="token punctuation">(</span><span class="token string">'scalar/scalars_test'</span><span class="token punctuation">,</span> <span class="token punctuation">{</span><span class="token string">'xsinx'</span><span class="token punctuation">:</span> epoch<span class="token operator">*</span>np<span class="token punctuation">.</span>sin<span class="token punctuation">(</span>epoch<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">'xcosx'</span><span class="token punctuation">:</span> epoch<span class="token operator">*</span>np<span class="token punctuation">.</span>cos<span class="token punctuation">(</span>epoch<span class="token punctuation">)</span><span class="token punctuation">}</span><span class="token punctuation">,</span> epoch<span class="token punctuation">)</span>writer<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span></code></pre><p>​        writer = Summarywriter()有两个参数(log_dir=None, comment=‘’, **kwargs)，其中log_dir为生成的文件所存放的目录，comment为文件名称，默认目录生成runs文件夹目录。</p><p><img src="C:%5CUsers%5Clxy%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5C1569274648075.png" alt="1569274648075"></p><p>​        当SummaryWriter(comment=’base_scalar’)，生成结果为：</p><p><img src="C:%5CUsers%5Clxy%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5C1569274748450.png" alt="1569274748450"></p><p>​        writer.add_scalar()，这句话是将我们需要的数据保存在文件里供可视化使用。第一个参数理解为保存的名称，第二个参数为Y轴数据，第三个参数为X轴数据。我们在runs同级目录下使用命令行：tensorboard –logdir runs，如下所示：</p><p><img src="C:%5CUsers%5Clxy%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5C1569275831694.png" alt="1569275831694"></p><p>​        最终的效果图如下：</p><p><img src="C:%5CUsers%5Clxy%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5C1569275879935.png" alt="1569275879935"></p>]]></content>
      
      
      
        <tags>
            
            <tag> Pytorch </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>《稀缺》解读</title>
      <link href="/2019/08/24/xi-que-jie-du/"/>
      <url>/2019/08/24/xi-que-jie-du/</url>
      
        <content type="html"><![CDATA[<p>为什么穷人越穷，富人越富？怎样才能摆脱稀缺心态，摆脱贫穷。</p><h2 id="稀缺的构成"><a href="#稀缺的构成" class="headerlink" title="稀缺的构成"></a>稀缺的构成</h2><p>作者认为长期的贫穷会带来一种稀缺心态。稀缺心态有个好处，会带来专注红利：短时间内集中精力爆发出高度注意力，比如Deadline之前的几天，是工作效率最高的时候；再比如永远是假期结束前的几天，我们会格外珍惜它。虽然如此的专注会在短时间内带来一定的好处，但如果长时间处在这种稀缺心态，会把一个人拖向贫穷，进入一个匮乏的恶性循环。</p><h2 id="稀缺的危害"><a href="#稀缺的危害" class="headerlink" title="稀缺的危害"></a>稀缺的危害</h2><p>稀缺会带来四种效应：</p><ul><li><p>管窥效应：</p><p>目光短浅，只关注眼前狭窄范围内的紧急事情，在意短时间内的成败与得失，而忽略了长久的发展与积累的技能叠加带来的长期的影响力。</p></li><li><p>借用：</p><p>让一个人习惯性的透支未来的资源，比如透支信用卡，工作拖到下一周，人们往往会高估自己在明天的能力从而不注意提升今天的自己，比如时间管理，精力管理，提高工作效率。</p></li><li><p>没有余闲：</p><p>稀缺会让人把大量的精力投入在了时间与金钱之间权衡的思维过程。因为这样的权衡会让一个人产生大量的心智负担，会消耗注意力、精力，进一步产生管窥效应，让人只注重眼前的事情、忽略了重要的事情。余闲可能会让人不是100%忙碌，但却让人从容地面对生活，不需要过多纠结于小事的权衡，以及有一定容错率。</p></li><li><p>带宽的不足：</p><p>带宽是我们计算能力、关注能力、决策能力、执行能力和抵制诱惑能力的统称，这些能力支撑了我们各种各样的行为。穷人不服药、不除草、不买保险、不储蓄、不投资，都是因为他们不重视这些事情，他们真正缺的不是时间、金钱，而是带宽，亦或是对于这些事情的认知能力。所以要关注长期规划，学习新的技能、定期理财，才有可能跳出稀缺的怪圈。</p></li></ul><h2 id="预防稀缺产生"><a href="#预防稀缺产生" class="headerlink" title="预防稀缺产生"></a>预防稀缺产生</h2><p>不要局限自己的眼光，要把它放长远些，这和吴军博士提到的“见识决定了你能走多远”是一个道理。我们需要</p><ul><li>节约带宽：不要把时间浪费在琐事上，集中在可以长期积累的事情上；</li><li>留有余闲：不要透支未来，定期存储、按时休息，设置提醒；</li><li>设置提醒：把重要的事情拉回到视野中引起重视；</li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> 读书 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>深度学习的Attenton机制</title>
      <link href="/2019/08/15/shen-du-xue-xi-de-attenton-ji-zhi/"/>
      <url>/2019/08/15/shen-du-xue-xi-de-attenton-ji-zhi/</url>
      
        <content type="html"><![CDATA[<h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p>​        通常在计算机视觉的深度学习算法中，Attention机制基本思想是让系统学会注意力，可以自动关注那些我们希望它关注的重点信息。</p><h1 id="Attention"><a href="#Attention" class="headerlink" title="Attention"></a>Attention</h1><p>​       通常Attention机制被分为soft attention和hard attention，目前接触的算法通常都是soft attention机制。</p><h2 id="Soft-Attention"><a href="#Soft-Attention" class="headerlink" title="Soft Attention"></a>Soft Attention</h2><h3 id="空间域"><a href="#空间域" class="headerlink" title="空间域"></a>空间域</h3><p>​        空间注意力表现在模型对于图像的不同位置的关注程度不同。当特征图大小为 H×W×C，空间注意力对应着大小为H×W的矩阵，该矩阵的每个位置对原特征图对应位置的像素来讲就是一个权重，pixel-wise multiply。</p><p><img src="https://img2018.cnblogs.com/blog/1665919/201905/1665919-20190507160648693-2046757003.png" alt="img"></p><h2 id="通道域"><a href="#通道域" class="headerlink" title="通道域"></a>通道域</h2><p>​        这种注意力主要分布在channel中，相当于对图像的不同通道的关注程度不同。当特征图大小为 H×W×C，通道注意力对应着大小为1×1×C的矩阵，每个位置对应原channel图像全部像素的一个权重，channel-wise multiply。</p><p><img src="https://img2018.cnblogs.com/blog/1665919/201905/1665919-20190507161354647-1211359587.png" alt="img"></p>]]></content>
      
      
      
        <tags>
            
            <tag> 论文 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Leetcode.155</title>
      <link href="/2019/08/12/leetcode.155/"/>
      <url>/2019/08/12/leetcode.155/</url>
      
        <content type="html"><![CDATA[<h2 id="155-最小栈"><a href="#155-最小栈" class="headerlink" title="155.最小栈"></a>155.最小栈</h2><ul><li>设定一个辅助栈，用来存放<strong>stack</strong>中最小值：<ul><li>push:每当push新值进来时，如果“小于等于”min_stack栈顶值，则一起push到min_stack，即更新了最小值；</li><li>pop:判断pop出去的元素值是否是min_stack栈顶元素值（即最小值），如果是则将min_stack栈顶元素一起pop，这样可以保证min_stack栈顶元素始终是stack中的最小</li><li>getMin:返回min_stack栈顶即可。</li></ul></li><li>min_stack的作用是对stack中的元素做标记，标记的原则是min_stack中元素一定是降序的（栈底最大栈顶最小）。换个角度理解，min_stack等价于遍历stack所有元素，把升序的数字都删除掉，留下一个从栈底到栈顶降序的栈。本题要求获取最小值的复杂度是O(1)，因此须构建辅助栈，在push与pop的过程中始终保持辅助栈为一个降序栈。</li><li>时间空间复杂度都为O(N)，获取最小值复杂度为O(1)。</li></ul><pre class=" language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">MinStack</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token triple-quoted-string string">"""        initialize your data structure here.        """</span>        self<span class="token punctuation">.</span>stack <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>        self<span class="token punctuation">.</span>min_stack <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token keyword">def</span> <span class="token function">push</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">:</span> int<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">></span> None<span class="token punctuation">:</span>    self<span class="token punctuation">.</span>stack<span class="token punctuation">.</span>append<span class="token punctuation">(</span>x<span class="token punctuation">)</span>    <span class="token keyword">if</span> <span class="token operator">not</span> self<span class="token punctuation">.</span>min_stack <span class="token operator">or</span> x <span class="token operator">&lt;=</span> self<span class="token punctuation">.</span>min_stack<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">:</span>         self<span class="token punctuation">.</span>min_stack<span class="token punctuation">.</span>append<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token keyword">def</span> <span class="token function">pop</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">></span> None<span class="token punctuation">:</span>    <span class="token keyword">if</span> self<span class="token punctuation">.</span>stack<span class="token punctuation">.</span>pop<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">==</span> self<span class="token punctuation">.</span>min_stack<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">:</span>        self<span class="token punctuation">.</span>min_stack<span class="token punctuation">.</span>pop<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">def</span> <span class="token function">top</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">></span> int<span class="token punctuation">:</span>    <span class="token keyword">return</span> self<span class="token punctuation">.</span>stack<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token keyword">def</span> <span class="token function">getMin</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">></span> int<span class="token punctuation">:</span>    <span class="token keyword">return</span> self<span class="token punctuation">.</span>min_stack<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span></code></pre>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>爱如半夜汽笛</title>
      <link href="/2019/08/12/ai-ru-ban-ye-qi-di/"/>
      <url>/2019/08/12/ai-ru-ban-ye-qi-di/</url>
      
        <content type="html"><![CDATA[<h1 id="《爱如半夜汽笛》—-村上春树"><a href="#《爱如半夜汽笛》—-村上春树" class="headerlink" title="《爱如半夜汽笛》—- 村上春树"></a>《爱如半夜汽笛》—- 村上春树</h1><p>女孩问男孩：“你喜欢我喜欢到什么程度？” </p><p>少年想了想，用沉静的声音说：“半夜汽笛那个程度。” </p><p>少女默默地等待下文—里面肯定有什么故事。</p><p>“一次，半夜突然醒来。”他开始讲述，“确切时间不清楚，大约两三点吧，也就那个时间。什么时候并不重要，总之是夜深时分，我完完全全孤单一人，身边谁也没有。好吗，请你想象一下：四下漆黑一片，什么也看不见，什么也听不见，就连时钟声都听不见，也可能钟停了。我忽然觉得自己正被隔离开来，远离自己认识的人，远离自己熟悉的场所，远得无法置信。在这广大世界上不为任何人爱，不为任何人理解，不为任何人记起—我发现自己成了这样的存在。即使我就这么消失不见，也没有人察觉。那种心情，简直就像被塞进厚铁箱沉入深海底。由于气压的关系，心脏开始痛，痛得像要咔哧咔哧裂成两半。这滋味你可知道？”<br>　　少女点点头。想必她是知道的。<br>　　少年继续说道：“这大概是人活着的过程中所能体验到的最难以忍受的一种感觉。又伤心又难受，恨不得直接死掉算了。不不，不是这样，不是死掉算了，而是假如放在那里不管，就真的死掉了，因为铁箱里的空气越来越稀薄了。这可不是什么比喻，是真的。这也就是深夜里孤单单醒来的含义。这你也明白？”<br>　　少女再次默默点头。少年停了一会儿。<br>　　“不过当时听见很远很远的地方有汽笛声，非常非常遥远。到底什么地方有铁路呢？莫名其妙。总之就那么远。声音若有若无，但我知道那是火车的汽笛声，肯定是。黑暗中我竖耳细听，于是又一次听到了汽笛声。很快，我的心脏不再痛了，时针开始走动，铁箱朝海面慢慢浮升。而这都是因为那微弱的汽笛声的关系。汽笛声的确微弱，听见没听见都分不清，而我就像爱那汽笛一样爱你。”<br>　　少年的短小故事至此结束。这回少女开始讲她自己的故事。</p>]]></content>
      
      
      
        <tags>
            
            <tag> 散文 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Pytorch实现PixelShuffle</title>
      <link href="/2019/08/10/pytorch-shi-xian-pixelshuffle/"/>
      <url>/2019/08/10/pytorch-shi-xian-pixelshuffle/</url>
      
        <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>​        今天在思考如何解决model在上采样过程中可能会出现的棋盘格现象，阅读到一篇被CVPR2016收录的论文，里面提出了PixelShuffle，链接如下<a href="https://links.jianshu.com/go?to=https%3A%2F%2Farxiv.org%2Fabs%2F1609.05158" target="_blank" rel="noopener">《Real-Time Single Image and Video Super-Resolution Using an Efficient Sub-Pixel Convolutional Neural Network》</a>。</p><h2 id="过程"><a href="#过程" class="headerlink" title="过程"></a>过程</h2><p>​        PixelShuffle算法流程图如下，可以实现将h<em>w的低分辨率图像，通过sub-pixel 操作变为rh</em>rw的高分辨率图像，通过卷积层先得到了r^2个通道的图像，然后每个像素点的r^2个通道依次转换为对应的r<em>r的图像块，最终得到rh</em>rw的图像。</p><p><img src="https://upload-images.jianshu.io/upload_images/7812018-c33b5e4567bb5024.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1000/format/webp" alt="img"></p><p>​        Pytorch中已经集成了PixelShuffle的module，torch.nn.PixelShuffle(upscale_factor)，形参说明: - input (Variable) – 输入 - upscale_factor (int) – 增加空间分辨率的因子，例子如下。</p><p><img src="https://upload-images.jianshu.io/upload_images/7812018-b2a078e48dfd3084.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1000/format/webp" alt="img"></p>]]></content>
      
      
      
        <tags>
            
            <tag> Pytorch </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hello World</title>
      <link href="/2019/08/10/hello-world/"/>
      <url>/2019/08/10/hello-world/</url>
      
        <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="noopener">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="noopener">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="noopener">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><pre class=" language-bash"><code class="language-bash">$ hexo new <span class="token string">"My New Post"</span></code></pre><p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="noopener">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><pre class=" language-bash"><code class="language-bash">$ hexo server</code></pre><p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="noopener">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><pre class=" language-bash"><code class="language-bash">$ hexo generate</code></pre><p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="noopener">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><pre class=" language-bash"><code class="language-bash">$ hexo deploy</code></pre><p>More info: <a href="https://hexo.io/docs/deployment.html" target="_blank" rel="noopener">Deployment</a></p>]]></content>
      
      
      
    </entry>
    
    
  
  
</search>
